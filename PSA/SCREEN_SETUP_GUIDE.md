# PSA Scraper Ubuntu Screen Setup - Complete Guide

## ğŸš€ Quick Start Commands

### Test Run (Dry Run)
```bash
./run_psa_scraper.sh --dry-run
```

### Production Run
```bash
./run_psa_scraper.sh
```

### Monitor Progress
```bash
./monitor_psa_scraper.sh
```

### Stop Scraper
```bash
./kill_psa_scraper.sh
```

## ğŸ“‹ Management Scripts

### 1. `run_psa_scraper.sh` - Main Launcher
- Creates screen session named "psa_scraper"
- Sets up comprehensive logging
- Handles PID tracking and process management
- Supports both dry-run and production modes

**Features:**
- âœ… Automatic screen installation check
- âœ… Prevents duplicate instances
- âœ… Comprehensive error logging
- âœ… Process ID tracking
- âœ… Graceful error handling

### 2. `monitor_psa_scraper.sh` - Real-time Monitor
- Live status dashboard with auto-refresh
- Shows CPU/memory usage
- Displays recent progress and errors
- Interactive commands for log viewing

**Monitor Commands:**
- `q` - Quit monitor
- `l` - View live logs
- `e` - View error logs  
- `s` - Attach to screen session
- `k` - Kill scraper

### 3. `kill_psa_scraper.sh` - Safe Termination
- Gracefully terminates scraper process
- Cleans up PID files and screen sessions
- Handles both running and stuck processes

### 4. `cleanup_logs.sh` - Log Management
- Removes logs older than 30 days
- Compresses logs larger than 100MB
- Shows disk space savings

## ğŸ“ Log Structure

```
logs/
â”œâ”€â”€ psa_production_YYYYMMDD_HHMMSS.log     # Main execution log
â”œâ”€â”€ psa_production_errors_YYYYMMDD_HHMMSS.log  # Error-only log
â”œâ”€â”€ psa_monitor_YYYYMMDD_HHMMSS.log        # Monitor session log
â””â”€â”€ psa_scraper.pid                        # Process ID file
```

## ğŸ”§ Screen Session Management

### Basic Commands
```bash
# List all screen sessions
screen -list

# Attach to PSA scraper session
screen -r psa_scraper

# Detach from session (while attached)
Ctrl+A, then D

# Kill session
screen -S psa_scraper -X quit
```

### Advanced Usage
```bash
# Create new window in session
Ctrl+A, then C

# Switch between windows
Ctrl+A, then N (next) or P (previous)

# View session logs
Ctrl+A, then H
```

## ğŸ“Š Expected Behavior

### Production Run Timeline
1. **Initialization** (0-30s)
   - BigQuery connection check
   - Duplicate detection scan
   - Card list loading

2. **Processing Phase** (~110 minutes)
   - 10 cards Ã— 19 grades = 190 API calls
   - 35-second delays between requests
   - Checkpoint saves every 2 cards

3. **Completion**
   - Final BigQuery load
   - Summary statistics
   - Log archival

### Log Patterns to Watch
```bash
# Success indicators
âœ… Success: ID 544027, Grade 10 - 1234 sales
ğŸ¯ Completed scraping for Charizard-Holo: 1500 total records
âœ… Loaded 1500 records to BigQuery

# Progress tracking
ğŸ´ Processing card 3/10: Machamp-Holo 1st Edition
ğŸ“Š Processing PSA 10 (1/19)
ğŸ“ˆ Progress: 3/10 cards | ETA: 14:25:30

# Error patterns
âŒ Failed to fetch data for ID 544027, Grade 10
âš ï¸ No data found for PSA 8.5 (404)
ğŸš¨ BigQuery load failed: Connection timeout
```

## ğŸš¨ Troubleshooting

### Scraper Won't Start
```bash
# Check for existing processes
ps aux | grep scrape_psa_production
screen -list

# Clean up manually
./kill_psa_scraper.sh
rm -f logs/psa_scraper.pid
```

### Screen Session Issues
```bash
# If screen not found
sudo apt update && sudo apt install screen

# If session exists but not responding
screen -S psa_scraper -X quit
./run_psa_scraper.sh
```

### Log File Problems
```bash
# Create logs directory
mkdir -p logs

# Check disk space
df -h .

# Clean up logs
./cleanup_logs.sh
```

### BigQuery Connection Issues
```bash
# Verify credentials
ls -la service-account.json
cat .env | grep GOOGLE

# Test connection
python -c "from google.cloud import bigquery; client = bigquery.Client(); print('Connection OK')"
```

## ğŸ’¡ Best Practices

### Before Starting
1. âœ… Verify BigQuery credentials work
2. âœ… Check available disk space (>1GB recommended)
3. âœ… Test with dry-run first
4. âœ… Ensure stable internet connection

### During Execution
1. âœ… Monitor progress with `./monitor_psa_scraper.sh`
2. âœ… Don't manually kill screen session
3. âœ… Check error logs if progress stalls
4. âœ… Keep terminal session active

### After Completion
1. âœ… Review final summary in logs
2. âœ… Run BigQuery deduplication queries
3. âœ… Archive log files
4. âœ… Clean up checkpoint files

## ğŸ¯ Success Indicators

```bash
# Check if scraper completed successfully
tail -20 logs/psa_production_*.log | grep -E "(SUCCESS|completed|Summary)"

# Verify data in BigQuery
# Use queries from bigquery_deduplication_queries.sql

# Expected final output
ğŸ“Š Total records processed: 25000+
ğŸŒ Total API calls: 190
âœ… Combinations processed this session: 190
```

Ready for production deployment! ğŸš€